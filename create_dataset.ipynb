{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a3d896-5d14-4502-af5a-e84597357c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/doitclap/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from itertools import islice\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a3b8b-9b0f-484b-ba30-b61ae56815c2",
   "metadata": {},
   "source": [
    "### Load into environment as Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb119956-1d7f-4839-adf7-b8768b1110a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_as_table = pd.read_csv('IMDB Dataset.csv')\n",
    "reviews_as_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed22779",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73c8311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_as_table = reviews_as_table.iloc[:1000,:]\n",
    "reviews_as_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3efa2c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbdc12b-4a17-4232-8fed-8a50c8bfb7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' START_TOKEN  a wonderful little production.  LINE_BREAK  LINE_BREAK  START_TOKEN the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece.  LINE_BREAK  LINE_BREAK  START_TOKEN the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too!  START_TOKEN you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece.  START_TOKEN a masterful production about one of the great master\\'s of comedy and his life.  LINE_BREAK  LINE_BREAK  START_TOKEN the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears.  START_TOKEN it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(x):\n",
    "    x = re.sub(r'[^\\x00-\\x7f]', r'', x) # remove unwanted ascii\n",
    "    x = x.lower() # set to lower\n",
    "    x = \"<s> \" + x # add start token at start\n",
    "\n",
    "    x = \" \".join(x.split()) # remove consecutive spaces\n",
    "\n",
    "    END_TOKENS = [\".\", \"!\", \"?\"]\n",
    "    for char in END_TOKENS:\n",
    "        x = x.replace(char + \" \", char + \" <s>\") # add start token at the end of every end token\n",
    "    x = x.replace(\"<br /><br />\", \"<br /><br /><s>\") # add start token at the end of double line breaks\n",
    "    x = x.replace(\"<s><br /><br /><s>\", \"<br /><br /><s>\") # remove start tokens at the start of double line breaks\n",
    "    x = x.replace(\"<s> <br /><br /><s>\", \"<br /><br /><s>\") # remove unlikely case just for safety\n",
    "    x = x.replace(\"<br />\", \" LINE_BREAK \").replace(\"<s>\", \" START_TOKEN \")\n",
    "\n",
    "    return x\n",
    "\n",
    "reviews_as_table[\"cleaned\"] = reviews_as_table[\"review\"].apply(foo)\n",
    "\n",
    "reviews_as_table[\"cleaned\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9ef08-cb64-4250-8f51-3545651d2189",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d39eb7-4b1b-44fb-8076-c97db8e72275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START_TOKEN',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'hooked',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " ',',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " ',',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'trust',\n",
       " 'me',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " ',',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city',\n",
       " ',',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " ',',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " '..',\n",
       " 'aryans',\n",
       " ',',\n",
       " 'muslims',\n",
       " ',',\n",
       " 'gangstas',\n",
       " ',',\n",
       " 'latinos',\n",
       " ',',\n",
       " 'christians',\n",
       " ',',\n",
       " 'italians',\n",
       " ',',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more',\n",
       " '....',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " ',',\n",
       " 'death',\n",
       " 'stares',\n",
       " ',',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'oz',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'i',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more',\n",
       " ',',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz',\n",
       " ',',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence',\n",
       " ',',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmates',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'well',\n",
       " 'mannered',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " ')',\n",
       " 'watching',\n",
       " 'oz',\n",
       " ',',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_as_table[\"tokenized\"] = reviews_as_table[\"cleaned\"].apply(lambda x: word_tokenize(x))\n",
    "reviews_as_table[\"tokenized\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb76f4-268e-4edb-883b-0f9a5babb88f",
   "metadata": {},
   "source": [
    "### obtaining `max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fd9fbc-f01b-4819-a37f-5f635c989f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = reviews_as_table[\"tokenized\"].apply(lambda x: len(x))\n",
    "max_length = counts.max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b23f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START_TOKEN',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'hooked',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " ',',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " ',',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'trust',\n",
       " 'me',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " ',',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city',\n",
       " ',',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " ',',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " '..',\n",
       " 'aryans',\n",
       " ',',\n",
       " 'muslims',\n",
       " ',',\n",
       " 'gangstas',\n",
       " ',',\n",
       " 'latinos',\n",
       " ',',\n",
       " 'christians',\n",
       " ',',\n",
       " 'italians',\n",
       " ',',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more',\n",
       " '....',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " ',',\n",
       " 'death',\n",
       " 'stares',\n",
       " ',',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'oz',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'i',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more',\n",
       " ',',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz',\n",
       " ',',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence',\n",
       " ',',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmates',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'well',\n",
       " 'mannered',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " ')',\n",
       " 'watching',\n",
       " 'oz',\n",
       " ',',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " 'NULL_TOKEN',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(x):\n",
    "    for _ in range(max_length - len(x)):\n",
    "        x.append(\"NULL_TOKEN\")\n",
    "    return x\n",
    "\n",
    "reviews_as_table[\"tokenized\"] = reviews_as_table[\"tokenized\"].apply(foo)\n",
    "reviews_as_table[\"tokenized\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb2941e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_as_table[\"tokenized\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923f300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['START_TOKEN',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'that',\n",
       " 'rotj',\n",
       " 'was',\n",
       " 'clearly',\n",
       " 'the',\n",
       " 'best',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'three',\n",
       " 'star',\n",
       " 'wars',\n",
       " 'movies',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'find',\n",
       " 'it',\n",
       " 'surprising',\n",
       " 'that',\n",
       " 'rotj',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'the',\n",
       " 'weakest',\n",
       " 'installment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'trilogy',\n",
       " 'by',\n",
       " 'many',\n",
       " 'who',\n",
       " 'have',\n",
       " 'voted',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'to',\n",
       " 'me',\n",
       " 'it',\n",
       " 'seemed',\n",
       " 'like',\n",
       " 'rotj',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'because',\n",
       " 'it',\n",
       " 'had',\n",
       " 'the',\n",
       " 'most',\n",
       " 'profound',\n",
       " 'plot',\n",
       " ',',\n",
       " 'the',\n",
       " 'most',\n",
       " 'suspense',\n",
       " ',',\n",
       " 'surprises',\n",
       " ',',\n",
       " 'most',\n",
       " 'emotional',\n",
       " ',',\n",
       " '(',\n",
       " 'especially',\n",
       " 'the',\n",
       " 'ending',\n",
       " ')',\n",
       " 'and',\n",
       " 'definitely',\n",
       " 'the',\n",
       " 'most',\n",
       " 'episodic',\n",
       " 'movie',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'personally',\n",
       " 'like',\n",
       " 'the',\n",
       " 'empire',\n",
       " 'strikes',\n",
       " 'back',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'also',\n",
       " 'but',\n",
       " 'i',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'slightly',\n",
       " 'less',\n",
       " 'good',\n",
       " 'than',\n",
       " 'than',\n",
       " 'rotj',\n",
       " 'since',\n",
       " 'it',\n",
       " 'was',\n",
       " 'slower-moving',\n",
       " ',',\n",
       " 'was',\n",
       " 'not',\n",
       " 'as',\n",
       " 'episodic',\n",
       " ',',\n",
       " 'and',\n",
       " 'i',\n",
       " 'just',\n",
       " 'did',\n",
       " 'not',\n",
       " 'feel',\n",
       " 'as',\n",
       " 'much',\n",
       " 'suspense',\n",
       " 'or',\n",
       " 'emotion',\n",
       " 'as',\n",
       " 'i',\n",
       " 'did',\n",
       " 'with',\n",
       " 'the',\n",
       " 'third',\n",
       " 'movie',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'also',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'to',\n",
       " 'me',\n",
       " 'that',\n",
       " 'after',\n",
       " 'reading',\n",
       " 'these',\n",
       " 'surprising',\n",
       " 'reviews',\n",
       " 'that',\n",
       " 'the',\n",
       " 'reasons',\n",
       " 'people',\n",
       " 'cited',\n",
       " 'for',\n",
       " 'rotj',\n",
       " 'being',\n",
       " 'an',\n",
       " 'inferior',\n",
       " 'film',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'two',\n",
       " 'are',\n",
       " 'just',\n",
       " 'plain',\n",
       " 'ludicrous',\n",
       " 'and',\n",
       " 'are',\n",
       " 'insignificant',\n",
       " 'reasons',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'the',\n",
       " 'sheer',\n",
       " 'excellence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'a',\n",
       " 'whole',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'many',\n",
       " 'strange',\n",
       " 'reasons',\n",
       " 'such',\n",
       " 'as',\n",
       " ':',\n",
       " 'a',\n",
       " ')',\n",
       " 'because',\n",
       " 'yoda',\n",
       " 'died',\n",
       " 'b',\n",
       " ')',\n",
       " 'because',\n",
       " 'bobba',\n",
       " 'fett',\n",
       " 'died',\n",
       " 'c',\n",
       " ')',\n",
       " 'because',\n",
       " 'small',\n",
       " 'ewoks',\n",
       " 'defeated',\n",
       " 'a',\n",
       " 'band',\n",
       " 'of',\n",
       " 'stormtroopers',\n",
       " 'd',\n",
       " ')',\n",
       " 'because',\n",
       " 'darth',\n",
       " 'vader',\n",
       " 'was',\n",
       " 'revealed',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'debunk',\n",
       " 'each',\n",
       " 'of',\n",
       " 'these',\n",
       " 'reasons',\n",
       " 'because',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'they',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'point',\n",
       " 'completely',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'first',\n",
       " 'off',\n",
       " ',',\n",
       " 'who',\n",
       " 'cares',\n",
       " 'if',\n",
       " 'bobba',\n",
       " 'fett',\n",
       " 'died',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'START_TOKEN',\n",
       " 'if',\n",
       " 'george',\n",
       " 'lucas',\n",
       " 'wanted',\n",
       " 'him',\n",
       " 'to',\n",
       " 'die',\n",
       " 'then',\n",
       " 'he',\n",
       " 'wanted',\n",
       " 'him',\n",
       " 'to',\n",
       " 'die',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'me',\n",
       " 'wrong',\n",
       " 'i',\n",
       " 'am',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'bobba',\n",
       " 'fett',\n",
       " 'but',\n",
       " 'he',\n",
       " 'made',\n",
       " 'a',\n",
       " 'few',\n",
       " 'cameo',\n",
       " 'appearances',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'lucas',\n",
       " \"'\",\n",
       " 'intention',\n",
       " 'to',\n",
       " 'make',\n",
       " 'him',\n",
       " 'a',\n",
       " 'central',\n",
       " 'character',\n",
       " 'in',\n",
       " 'the',\n",
       " 'films',\n",
       " 'that',\n",
       " 'star',\n",
       " 'wars',\n",
       " 'fans',\n",
       " 'made',\n",
       " 'him',\n",
       " 'out',\n",
       " 'to',\n",
       " 'be',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'his',\n",
       " 'name',\n",
       " 'was',\n",
       " 'not',\n",
       " 'even',\n",
       " 'mentioned',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'movie',\n",
       " '...',\n",
       " 'START_TOKEN',\n",
       " 'you',\n",
       " 'had',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'credits',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'bobba',\n",
       " 'fett',\n",
       " \"'s\",\n",
       " 'name',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'judging',\n",
       " 'rotj',\n",
       " 'because',\n",
       " 'a',\n",
       " 'minor',\n",
       " 'character',\n",
       " 'died',\n",
       " 'is',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'much',\n",
       " 'i',\n",
       " 'think',\n",
       " '...',\n",
       " 'START_TOKEN',\n",
       " 'secondly',\n",
       " ',',\n",
       " 'many',\n",
       " 'fans',\n",
       " 'did',\n",
       " 'not',\n",
       " 'like',\n",
       " 'yoda',\n",
       " 'dying',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'sure',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'a',\n",
       " 'momentous',\n",
       " 'period',\n",
       " 'in',\n",
       " 'the',\n",
       " 'movie',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'was',\n",
       " 'not',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'see',\n",
       " 'him',\n",
       " 'die',\n",
       " 'either',\n",
       " 'but',\n",
       " 'it',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'more',\n",
       " 'realistic',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'all',\n",
       " 'the',\n",
       " 'good',\n",
       " 'guys',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'stay',\n",
       " 'alive',\n",
       " 'in',\n",
       " 'a',\n",
       " 'realistic',\n",
       " 'movie',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'otherwise',\n",
       " 'if',\n",
       " 'all',\n",
       " 'the',\n",
       " 'good',\n",
       " 'guys',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'all',\n",
       " 'the',\n",
       " 'bad',\n",
       " 'guys',\n",
       " 'died',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'tantamount',\n",
       " 'to',\n",
       " 'a',\n",
       " 'cheesy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'cartoon',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'another',\n",
       " 'aspect',\n",
       " 'to',\n",
       " 'this',\n",
       " 'point',\n",
       " 'about',\n",
       " 'people',\n",
       " 'not',\n",
       " 'liking',\n",
       " 'yoda',\n",
       " \"'s\",\n",
       " 'death',\n",
       " '..',\n",
       " 'START_TOKEN',\n",
       " 'well',\n",
       " ',',\n",
       " 'nobody',\n",
       " 'complained',\n",
       " 'when',\n",
       " 'darth',\n",
       " 'vader',\n",
       " 'struck',\n",
       " 'down',\n",
       " 'obi',\n",
       " 'wan',\n",
       " 'kenobi',\n",
       " 'in',\n",
       " 'a',\n",
       " 'new',\n",
       " 'hope',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " '(',\n",
       " 'many',\n",
       " 'consider',\n",
       " 'a',\n",
       " 'new',\n",
       " 'hope',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trilogy',\n",
       " ')',\n",
       " 'why',\n",
       " 'was',\n",
       " 'obi',\n",
       " 'wan',\n",
       " \"'s\",\n",
       " 'death',\n",
       " 'okay',\n",
       " 'but',\n",
       " 'yoda',\n",
       " \"'s\",\n",
       " 'not',\n",
       " '...',\n",
       " 'START_TOKEN',\n",
       " 'hmmmmmmmmmmmm',\n",
       " '....',\n",
       " 'START_TOKEN',\n",
       " 'another',\n",
       " 'reason',\n",
       " 'i',\n",
       " 'just',\n",
       " 'can',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'was',\n",
       " 'even',\n",
       " 'stated',\n",
       " 'was',\n",
       " 'because',\n",
       " 'people',\n",
       " 'found',\n",
       " 'cute',\n",
       " 'ewoks',\n",
       " 'overpowering',\n",
       " 'stormtroopers',\n",
       " 'to',\n",
       " 'be',\n",
       " 'impossible',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'that',\n",
       " 'is',\n",
       " 'utterly',\n",
       " 'ridiculous',\n",
       " '!',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'can',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'this',\n",
       " 'one',\n",
       " '!',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'first',\n",
       " 'off',\n",
       " ',',\n",
       " 'the',\n",
       " 'ewoks',\n",
       " 'are',\n",
       " 'in',\n",
       " 'their',\n",
       " 'native',\n",
       " 'planet',\n",
       " 'endor',\n",
       " 'so',\n",
       " 'they',\n",
       " 'are',\n",
       " 'cognizant',\n",
       " 'of',\n",
       " 'their',\n",
       " 'home',\n",
       " 'terrain',\n",
       " 'since',\n",
       " 'they',\n",
       " 'live',\n",
       " 'there',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'if',\n",
       " 'you',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'carefully',\n",
       " 'many',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tactics',\n",
       " 'the',\n",
       " 'ewoks',\n",
       " 'used',\n",
       " 'in',\n",
       " 'defeating',\n",
       " 'the',\n",
       " 'stormtroopers',\n",
       " 'was',\n",
       " 'through',\n",
       " 'excellent',\n",
       " 'use',\n",
       " 'of',\n",
       " 'their',\n",
       " 'home',\n",
       " 'field',\n",
       " 'advantage',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " '(',\n",
       " 'since',\n",
       " 'you',\n",
       " 'lived',\n",
       " 'in',\n",
       " 'the',\n",
       " 'forest',\n",
       " 'all',\n",
       " 'your',\n",
       " 'life',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'would',\n",
       " 'have',\n",
       " 'learned',\n",
       " 'to',\n",
       " 'use',\n",
       " 'it',\n",
       " 'to',\n",
       " 'your',\n",
       " 'advantage',\n",
       " ')',\n",
       " 'they',\n",
       " 'had',\n",
       " 'swinging',\n",
       " 'vines',\n",
       " ',',\n",
       " 'ropes',\n",
       " ',',\n",
       " 'logs',\n",
       " 'set',\n",
       " 'up',\n",
       " 'to',\n",
       " 'trip',\n",
       " 'those',\n",
       " 'walkers',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'traps',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'stormtroopers',\n",
       " 'were',\n",
       " 'highly',\n",
       " 'disadvantaged',\n",
       " 'because',\n",
       " 'they',\n",
       " 'were',\n",
       " 'outnumbered',\n",
       " 'and',\n",
       " 'not',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'advantages',\n",
       " 'of',\n",
       " 'the',\n",
       " 'forest',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'only',\n",
       " 'thing',\n",
       " 'they',\n",
       " 'had',\n",
       " 'was',\n",
       " 'their',\n",
       " 'blasters',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'to',\n",
       " 'add',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'like',\n",
       " 'the',\n",
       " 'ewoks',\n",
       " 'were',\n",
       " 'battling',\n",
       " 'the',\n",
       " 'stormtroopers',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'they',\n",
       " 'were',\n",
       " 'heavily',\n",
       " 'assisted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'band',\n",
       " 'of',\n",
       " 'rebels',\n",
       " 'in',\n",
       " 'that',\n",
       " 'conquest',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'that',\n",
       " 'if',\n",
       " 'the',\n",
       " 'stormtroopers',\n",
       " 'were',\n",
       " 'to',\n",
       " 'have',\n",
       " 'defeated',\n",
       " 'a',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'the',\n",
       " 'star',\n",
       " 'wars',\n",
       " 'heros',\n",
       " ',',\n",
       " 'the',\n",
       " 'band',\n",
       " 'of',\n",
       " 'rebels',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'huge',\n",
       " 'clan',\n",
       " 'of',\n",
       " 'ewoks',\n",
       " 'with',\n",
       " 'great',\n",
       " 'familiarity',\n",
       " 'of',\n",
       " 'their',\n",
       " 'home',\n",
       " 'terrain',\n",
       " ',',\n",
       " 'that',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'a',\n",
       " 'great',\n",
       " 'upset',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'lastly',\n",
       " ',',\n",
       " 'if',\n",
       " 'this',\n",
       " 'scene',\n",
       " 'was',\n",
       " 'still',\n",
       " 'unbelievable',\n",
       " 'to',\n",
       " 'you',\n",
       " '..',\n",
       " 'START_TOKEN',\n",
       " 'how',\n",
       " 'about',\n",
       " 'in',\n",
       " 'empire',\n",
       " 'strikes',\n",
       " 'back',\n",
       " 'or',\n",
       " 'in',\n",
       " 'a',\n",
       " 'new',\n",
       " 'hope',\n",
       " 'where',\n",
       " 'there',\n",
       " 'were',\n",
       " 'several',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'a',\n",
       " 'group',\n",
       " 'consisting',\n",
       " 'of',\n",
       " 'just',\n",
       " 'han',\n",
       " 'solo',\n",
       " ',',\n",
       " 'chewbacca',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'princess',\n",
       " ',',\n",
       " 'being',\n",
       " 'shot',\n",
       " 'at',\n",
       " 'by',\n",
       " 'like',\n",
       " 'ten',\n",
       " 'stormtroopers',\n",
       " 'and',\n",
       " 'all',\n",
       " 'their',\n",
       " 'blasters',\n",
       " 'missed',\n",
       " 'while',\n",
       " 'the',\n",
       " 'heros',\n",
       " 'were',\n",
       " 'in',\n",
       " 'full',\n",
       " 'view',\n",
       " '!',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'and',\n",
       " 'not',\n",
       " 'only',\n",
       " 'that',\n",
       " ',',\n",
       " 'the',\n",
       " 'heroes',\n",
       " ',',\n",
       " 'of',\n",
       " 'course',\n",
       " ',',\n",
       " 'always',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'stormtroopers',\n",
       " 'with',\n",
       " 'their',\n",
       " 'blasters',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'troopers',\n",
       " 'must',\n",
       " 'have',\n",
       " 'very',\n",
       " ',',\n",
       " 'very',\n",
       " 'bad',\n",
       " 'aim',\n",
       " 'then',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'at',\n",
       " 'least',\n",
       " 'in',\n",
       " 'empire',\n",
       " 'strikes',\n",
       " 'back',\n",
       " ',',\n",
       " 'the',\n",
       " 'battle',\n",
       " 'of',\n",
       " 'endor',\n",
       " 'was',\n",
       " 'much',\n",
       " 'more',\n",
       " 'believable',\n",
       " 'since',\n",
       " 'you',\n",
       " 'had',\n",
       " 'two',\n",
       " 'armies',\n",
       " 'pitted',\n",
       " 'each',\n",
       " 'other',\n",
       " 'not',\n",
       " '3',\n",
       " 'heroes',\n",
       " 'against',\n",
       " 'a',\n",
       " 'legion',\n",
       " 'of',\n",
       " 'stormtroopers',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'believe',\n",
       " 'me',\n",
       " '?',\n",
       " 'START_TOKEN',\n",
       " 'check',\n",
       " 'out',\n",
       " 'the',\n",
       " 'battle',\n",
       " 'at',\n",
       " 'cloud',\n",
       " 'city',\n",
       " 'when',\n",
       " 'our',\n",
       " 'heroes',\n",
       " 'were',\n",
       " 'escaping',\n",
       " 'lando',\n",
       " \"'s\",\n",
       " 'base',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'or',\n",
       " 'when',\n",
       " 'our',\n",
       " 'heros',\n",
       " 'were',\n",
       " 'rescuing',\n",
       " 'princess',\n",
       " 'leia',\n",
       " 'and',\n",
       " 'being',\n",
       " 'shot',\n",
       " 'at',\n",
       " '(',\n",
       " 'somehow',\n",
       " 'they',\n",
       " 'missed',\n",
       " ')',\n",
       " 'as',\n",
       " 'han',\n",
       " 'solo',\n",
       " 'and',\n",
       " 'luke',\n",
       " 'were',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'exit',\n",
       " 'the',\n",
       " 'death',\n",
       " 'star',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'last',\n",
       " 'reason',\n",
       " 'that',\n",
       " 'i',\n",
       " 'care',\n",
       " 'to',\n",
       " 'discuss',\n",
       " '(',\n",
       " 'others',\n",
       " 'are',\n",
       " 'just',\n",
       " 'too',\n",
       " 'plain',\n",
       " 'ridiculous',\n",
       " 'for',\n",
       " 'me',\n",
       " 'to',\n",
       " 'spend',\n",
       " 'my',\n",
       " 'time',\n",
       " 'here',\n",
       " '.',\n",
       " ')',\n",
       " 'is',\n",
       " 'that',\n",
       " 'people',\n",
       " 'did',\n",
       " 'not',\n",
       " 'like',\n",
       " 'darth',\n",
       " 'vader',\n",
       " 'being',\n",
       " 'revealed',\n",
       " '!',\n",
       " 'START_TOKEN',\n",
       " 'well',\n",
       " ',',\n",
       " 'in',\n",
       " 'many',\n",
       " 'ways',\n",
       " 'that',\n",
       " 'was',\n",
       " 'a',\n",
       " 'major',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'in',\n",
       " 'the',\n",
       " 'movie',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'luke',\n",
       " 'was',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'find',\n",
       " 'whether',\n",
       " 'or',\n",
       " 'not',\n",
       " 'darth',\n",
       " 'vader',\n",
       " 'was',\n",
       " 'his',\n",
       " 'father',\n",
       " ',',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curious to see what the longest review is, and if the start tokens were implemented properly\n",
    "\n",
    "for index, row in reviews_as_table.iterrows():\n",
    "    if 'NULL_TOKEN' not in row['tokenized']:\n",
    "        longest = row['tokenized']\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca96fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50e8482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annakin',\n",
       " 'skywalker',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'disappointing',\n",
       " 'if',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'had',\n",
       " 'ended',\n",
       " 'without',\n",
       " 'luke',\n",
       " 'getting',\n",
       " 'to',\n",
       " 'see',\n",
       " 'his',\n",
       " 'father',\n",
       " \"'s\",\n",
       " 'face',\n",
       " 'because',\n",
       " 'it',\n",
       " 'made',\n",
       " 'it',\n",
       " 'complete',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'by',\n",
       " 'annakin',\n",
       " \"'s\",\n",
       " 'revelation',\n",
       " 'it',\n",
       " 'symbolized',\n",
       " 'the',\n",
       " 'transition',\n",
       " 'darth',\n",
       " 'vader',\n",
       " 'underwent',\n",
       " 'from',\n",
       " 'being',\n",
       " 'possessed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'side',\n",
       " '(',\n",
       " 'in',\n",
       " 'his',\n",
       " 'helmet',\n",
       " ')',\n",
       " 'and',\n",
       " 'to',\n",
       " 'the',\n",
       " 'good',\n",
       " 'person',\n",
       " 'he',\n",
       " 'was',\n",
       " 'annakin',\n",
       " 'skywalker',\n",
       " '(',\n",
       " 'by',\n",
       " 'removing',\n",
       " 'the',\n",
       " 'helmet',\n",
       " ')',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'the',\n",
       " 'point',\n",
       " 'is',\n",
       " 'that',\n",
       " 'annakin',\n",
       " 'died',\n",
       " 'converted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'light',\n",
       " 'side',\n",
       " 'again',\n",
       " 'and',\n",
       " 'that',\n",
       " 'is',\n",
       " 'what',\n",
       " 'the',\n",
       " 'meaning',\n",
       " 'of',\n",
       " 'the',\n",
       " 'helmet',\n",
       " 'removal',\n",
       " 'scene',\n",
       " 'was',\n",
       " 'about',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'in',\n",
       " 'fact',\n",
       " ',',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'what',\n",
       " 'i',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'in',\n",
       " 'that',\n",
       " 'scene',\n",
       " 'too',\n",
       " 'if',\n",
       " 'i',\n",
       " 'were',\n",
       " 'luke',\n",
       " \"'s\",\n",
       " 'father',\n",
       " '...',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'that',\n",
       " 'what',\n",
       " 'you',\n",
       " 'would',\n",
       " 'have',\n",
       " 'done',\n",
       " 'if',\n",
       " 'you',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'see',\n",
       " 'your',\n",
       " 'son',\n",
       " 'with',\n",
       " 'your',\n",
       " 'own',\n",
       " 'eyes',\n",
       " 'before',\n",
       " 'you',\n",
       " 'died',\n",
       " 'and',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mechanized',\n",
       " 'helmet',\n",
       " '?',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'on',\n",
       " 'another',\n",
       " 'note',\n",
       " ',',\n",
       " 'i',\n",
       " 'think',\n",
       " 'a',\n",
       " 'subconscious',\n",
       " 'or',\n",
       " 'conscious',\n",
       " 'expectation',\n",
       " 'among',\n",
       " 'most',\n",
       " 'people',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'sequel',\n",
       " 'must',\n",
       " 'be',\n",
       " 'worse',\n",
       " '(',\n",
       " 'even',\n",
       " 'if',\n",
       " 'it',\n",
       " 'is',\n",
       " 'better',\n",
       " ')',\n",
       " 'that',\n",
       " 'preceding',\n",
       " 'movies',\n",
       " 'is',\n",
       " 'another',\n",
       " 'reason',\n",
       " 'that',\n",
       " 'rotj',\n",
       " 'does',\n",
       " 'not',\n",
       " 'get',\n",
       " 'as',\n",
       " 'many',\n",
       " 'accolades',\n",
       " 'as',\n",
       " 'it',\n",
       " 'deserves',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'never',\n",
       " 'go',\n",
       " 'into',\n",
       " 'a',\n",
       " 'film',\n",
       " 'with',\n",
       " 'that',\n",
       " 'deception',\n",
       " 'in',\n",
       " 'mind',\n",
       " ',',\n",
       " 'i',\n",
       " 'always',\n",
       " 'try',\n",
       " 'to',\n",
       " 'go',\n",
       " 'into',\n",
       " 'a',\n",
       " 'film',\n",
       " 'with',\n",
       " 'the',\n",
       " 'attitude',\n",
       " 'that',\n",
       " '``',\n",
       " 'well',\n",
       " ',',\n",
       " 'it',\n",
       " 'might',\n",
       " 'be',\n",
       " 'better',\n",
       " 'or',\n",
       " 'worse',\n",
       " 'that',\n",
       " 'the',\n",
       " 'original',\n",
       " '..',\n",
       " 'START_TOKEN',\n",
       " 'but',\n",
       " 'i',\n",
       " 'can',\n",
       " 'not',\n",
       " 'know',\n",
       " 'for',\n",
       " 'sure',\n",
       " '..',\n",
       " 'START_TOKEN',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'see',\n",
       " '.',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'way',\n",
       " 'i',\n",
       " 'go',\n",
       " 'with',\n",
       " 'an',\n",
       " 'open',\n",
       " 'mind',\n",
       " 'and',\n",
       " 'do',\n",
       " 'not',\n",
       " 'dupe',\n",
       " 'myself',\n",
       " 'into',\n",
       " 'thinking',\n",
       " 'that',\n",
       " 'a',\n",
       " 'clearly',\n",
       " 'superior',\n",
       " 'film',\n",
       " 'is',\n",
       " 'not',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'it',\n",
       " 'really',\n",
       " 'was',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'who',\n",
       " 'criticizes',\n",
       " 'these',\n",
       " 'movies',\n",
       " 'but',\n",
       " ',',\n",
       " 'i',\n",
       " 'have',\n",
       " 'asked',\n",
       " 'many',\n",
       " 'college',\n",
       " 'students',\n",
       " 'and',\n",
       " 'adults',\n",
       " 'about',\n",
       " 'which',\n",
       " 'is',\n",
       " 'their',\n",
       " 'favorite',\n",
       " 'star',\n",
       " 'wars',\n",
       " 'movie',\n",
       " 'and',\n",
       " 'they',\n",
       " 'all',\n",
       " 'tell',\n",
       " 'me',\n",
       " '(',\n",
       " 'except',\n",
       " 'for',\n",
       " 'one',\n",
       " 'person',\n",
       " 'that',\n",
       " 'said',\n",
       " 'that',\n",
       " 'a',\n",
       " 'new',\n",
       " 'hope',\n",
       " 'was',\n",
       " 'their',\n",
       " 'favorite',\n",
       " ')',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'rotj',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'the',\n",
       " 'results',\n",
       " 'on',\n",
       " 'these',\n",
       " 'polls',\n",
       " 'are',\n",
       " 'appalling',\n",
       " 'and',\n",
       " 'quite',\n",
       " 'misleading',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'bottom',\n",
       " 'line',\n",
       " ',',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'the',\n",
       " 'jedi',\n",
       " 'was',\n",
       " 'the',\n",
       " 'best',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trilogy',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'was',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'three',\n",
       " 'that',\n",
       " 'kept',\n",
       " 'me',\n",
       " 'riveted',\n",
       " 'all',\n",
       " 'throughout',\n",
       " 'its',\n",
       " '135',\n",
       " 'minutes',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'there',\n",
       " 'was',\n",
       " 'not',\n",
       " 'a',\n",
       " 'moment',\n",
       " 'of',\n",
       " 'boredom',\n",
       " 'because',\n",
       " 'each',\n",
       " 'scene',\n",
       " 'was',\n",
       " 'either',\n",
       " 'suspenseful',\n",
       " ',',\n",
       " 'exciting',\n",
       " ',',\n",
       " 'surprising',\n",
       " ',',\n",
       " 'or',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'above',\n",
       " '.',\n",
       " 'START_TOKEN',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'the',\n",
       " 'emotional',\n",
       " 'light',\n",
       " 'saber',\n",
       " 'battle',\n",
       " 'between',\n",
       " 'luke',\n",
       " 'and',\n",
       " 'his',\n",
       " 'father',\n",
       " 'in',\n",
       " 'rotj',\n",
       " 'was',\n",
       " 'better',\n",
       " 'than',\n",
       " 'the',\n",
       " 'one',\n",
       " 'in',\n",
       " 'the',\n",
       " 'empire',\n",
       " 'strikes',\n",
       " 'back',\n",
       " 'any',\n",
       " 'day',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN',\n",
       " 'finally',\n",
       " ',',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'people',\n",
       " 'go',\n",
       " 'see',\n",
       " 'the',\n",
       " 'phantom',\n",
       " 'menace',\n",
       " 'with',\n",
       " 'an',\n",
       " 'open',\n",
       " 'mind',\n",
       " 'because',\n",
       " 'if',\n",
       " 'fans',\n",
       " 'start',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'nitpicky',\n",
       " ',',\n",
       " 'insignificant',\n",
       " 'details',\n",
       " '(',\n",
       " 'or',\n",
       " 'see',\n",
       " 'it',\n",
       " 'as',\n",
       " '``',\n",
       " 'just',\n",
       " 'another',\n",
       " 'sequel',\n",
       " \"''\",\n",
       " ')',\n",
       " 'to',\n",
       " 'trash',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'such',\n",
       " 'as',\n",
       " '``',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'stinks',\n",
       " 'because',\n",
       " 'luke',\n",
       " 'is',\n",
       " 'not',\n",
       " 'in',\n",
       " 'it',\n",
       " '!',\n",
       " \"''\",\n",
       " 'then',\n",
       " 'this',\n",
       " 'meritorious',\n",
       " 'film',\n",
       " 'will',\n",
       " 'become',\n",
       " 'another',\n",
       " 'spectacular',\n",
       " 'movie',\n",
       " 'that',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'of',\n",
       " 'derision',\n",
       " 'like',\n",
       " 'rotj',\n",
       " 'suffered',\n",
       " 'unfortunately',\n",
       " '.',\n",
       " 'LINE_BREAK',\n",
       " 'LINE_BREAK',\n",
       " 'START_TOKEN']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019264c7-e015-4f6a-81b0-7435f2c2d445",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "226181fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bullying\n",
      "premier\n",
      "mystery\n",
      "assure\n",
      "conceivable\n",
      "unflinching\n",
      "turned\n",
      "particular\n",
      "looking\n",
      "interpreters\n"
     ]
    }
   ],
   "source": [
    "vocab = set(reviews_as_table['tokenized'].explode().tolist())\n",
    "for i, val in enumerate(islice(vocab, 10)):\n",
    "    print(val)\n",
    "    # do not print vocab in its entirety as it blows up the file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c213059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'bullying'), (1, 'premier'), (2, 'mystery'), (3, 'assure'), (4, 'conceivable'), (5, 'unflinching'), (6, 'turned'), (7, 'particular'), (8, 'looking'), (9, 'interpreters')]\n",
      "[('bullying', 0), ('premier', 1), ('mystery', 2), ('assure', 3), ('conceivable', 4), ('unflinching', 5), ('turned', 6), ('particular', 7), ('looking', 8), ('interpreters', 9)]\n"
     ]
    }
   ],
   "source": [
    "idx_to_tkn = dict()\n",
    "tkn_to_idx = dict()\n",
    "\n",
    "for i, val in enumerate(vocab):\n",
    "    idx_to_tkn[i] = val\n",
    "    tkn_to_idx[val] = i\n",
    "\n",
    "print(list(islice(idx_to_tkn.items(), 10)))\n",
    "print(list(islice(tkn_to_idx.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e0cc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x1514</th>\n",
       "      <th>x1515</th>\n",
       "      <th>x1516</th>\n",
       "      <th>x1517</th>\n",
       "      <th>x1518</th>\n",
       "      <th>x1519</th>\n",
       "      <th>x1520</th>\n",
       "      <th>x1521</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16873</td>\n",
       "      <td>4461</td>\n",
       "      <td>1358</td>\n",
       "      <td>16459</td>\n",
       "      <td>17069</td>\n",
       "      <td>15270</td>\n",
       "      <td>17018</td>\n",
       "      <td>17850</td>\n",
       "      <td>2645</td>\n",
       "      <td>11639</td>\n",
       "      <td>...</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16873</td>\n",
       "      <td>6836</td>\n",
       "      <td>13769</td>\n",
       "      <td>14426</td>\n",
       "      <td>10141</td>\n",
       "      <td>17968</td>\n",
       "      <td>10774</td>\n",
       "      <td>10774</td>\n",
       "      <td>16873</td>\n",
       "      <td>16459</td>\n",
       "      <td>...</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16873</td>\n",
       "      <td>4575</td>\n",
       "      <td>16785</td>\n",
       "      <td>14295</td>\n",
       "      <td>1042</td>\n",
       "      <td>6836</td>\n",
       "      <td>13769</td>\n",
       "      <td>1191</td>\n",
       "      <td>6913</td>\n",
       "      <td>8524</td>\n",
       "      <td>...</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16873</td>\n",
       "      <td>5934</td>\n",
       "      <td>11631</td>\n",
       "      <td>19305</td>\n",
       "      <td>6836</td>\n",
       "      <td>2485</td>\n",
       "      <td>7785</td>\n",
       "      <td>6836</td>\n",
       "      <td>14426</td>\n",
       "      <td>6151</td>\n",
       "      <td>...</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16873</td>\n",
       "      <td>17219</td>\n",
       "      <td>10203</td>\n",
       "      <td>19305</td>\n",
       "      <td>6372</td>\n",
       "      <td>66</td>\n",
       "      <td>4279</td>\n",
       "      <td>16459</td>\n",
       "      <td>19112</td>\n",
       "      <td>1358</td>\n",
       "      <td>...</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>6951</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0     x1     x2     x3     x4     x5     x6     x7     x8     x9  ...  \\\n",
       "0  16873   4461   1358  16459  17069  15270  17018  17850   2645  11639  ...   \n",
       "1  16873   6836  13769  14426  10141  17968  10774  10774  16873  16459  ...   \n",
       "2  16873   4575  16785  14295   1042   6836  13769   1191   6913   8524  ...   \n",
       "3  16873   5934  11631  19305   6836   2485   7785   6836  14426   6151  ...   \n",
       "4  16873  17219  10203  19305   6372     66   4279  16459  19112   1358  ...   \n",
       "\n",
       "   x1514  x1515  x1516  x1517  x1518  x1519  x1520  x1521  y0  y1  \n",
       "0   6951   6951   6951   6951   6951   6951   6951   6951   1   0  \n",
       "1   6951   6951   6951   6951   6951   6951   6951   6951   1   0  \n",
       "2   6951   6951   6951   6951   6951   6951   6951   6951   1   0  \n",
       "3   6951   6951   6951   6951   6951   6951   6951   6951   0   1  \n",
       "4   6951   6951   6951   6951   6951   6951   6951   6951   1   0  \n",
       "\n",
       "[5 rows x 1524 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo():\n",
    "    l = []\n",
    "\n",
    "    def closure(x):\n",
    "        nonlocal l\n",
    "        if x['sentiment'] == 'positive':\n",
    "            t = [1,0]\n",
    "        else:\n",
    "            t = [0,1]\n",
    "        l2 = [tkn_to_idx[tkn] for tkn in x['tokenized']]\n",
    "        l.append(l2 + t)\n",
    "    return closure, l\n",
    "\n",
    "bar, table = foo()\n",
    "reviews_as_table.apply(bar, axis=1)\n",
    "\n",
    "df = pd.DataFrame(table, columns=['x' + str(i) for i in range(max_length)] + ['y0', 'y1'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf29431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
